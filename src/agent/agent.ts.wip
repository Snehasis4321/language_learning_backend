/**
 * Language Teacher Agent (Node.js version)
 * Simplified agent for voice conversations
 */

import {
  Room,
  RoomEvent,
  RemoteParticipant,
  RemoteTrackPublication,
  RemoteTrack,
  TrackKind,
} from 'livekit-client';
import { cerebrasService } from '../services/cerebras.service';
import { CerebrasMessage, DifficultyLevel } from '../types/conversation';

export class LanguageTeacherAgent {
  private room: Room;
  private conversationHistory: CerebrasMessage[] = [];
  private difficulty: DifficultyLevel = 'beginner';
  private topic?: string;
  private isProcessing = false;

  constructor() {
    this.room = new Room();
    this.setupEventListeners();
  }

  /**
   * Connect agent to a LiveKit room
   */
  async connect(
    url: string,
    token: string,
    metadata?: { difficulty?: DifficultyLevel; topic?: string }
  ): Promise<void> {
    if (metadata) {
      this.difficulty = metadata.difficulty || 'beginner';
      this.topic = metadata.topic;
    }

    await this.room.connect(url, token);
    console.log(`Agent connected to room: ${this.room.name}`);

    // Send initial greeting
    await this.speak(
      "Hello! I'm your language teacher. Let's practice speaking together. " +
        'What would you like to talk about?'
    );
  }

  /**
   * Set up event listeners for room events
   */
  private setupEventListeners(): void {
    this.room
      .on(RoomEvent.TrackSubscribed, this.handleTrackSubscribed.bind(this))
      .on(RoomEvent.TrackUnsubscribed, () => console.log('Track unsubscribed'))
      .on(RoomEvent.Disconnected, () => console.log('Agent disconnected'))
      .on(RoomEvent.ParticipantConnected, (participant: RemoteParticipant) => {
        console.log('Participant connected:', participant.identity);
      });
  }

  /**
   * Handle incoming audio tracks from users
   */
  private async handleTrackSubscribed(
    track: RemoteTrack,
    _publication: RemoteTrackPublication,
    participant: RemoteParticipant
  ): Promise<void> {
    console.log('Track subscribed:', track.kind);

    if (track.kind === TrackKind.Audio) {
      // TODO: Implement speech-to-text processing
      // For now, we'll just acknowledge that we're receiving audio
      console.log('Receiving audio from:', participant.identity);

      // In production, you would:
      // 1. Stream audio chunks to STT service (Cartesia/Whisper)
      // 2. Get transcript
      // 3. Send to Cerebras
      // 4. Convert response to speech
      // 5. Play back to room
    }
  }

  /**
   * Process user speech (text) and generate response
   */
  async processUserSpeech(userText: string): Promise<string> {
    if (this.isProcessing) {
      return '';
    }

    this.isProcessing = true;

    try {
      // Add user message to history
      this.conversationHistory.push({
        role: 'user',
        content: userText,
      });

      // Generate response using Cerebras
      const response = await cerebrasService.generateResponse(
        userText,
        this.conversationHistory,
        this.difficulty,
        this.topic
      );

      // Add assistant response to history
      this.conversationHistory.push({
        role: 'assistant',
        content: response,
      });

      // Speak the response
      await this.speak(response);

      return response;
    } catch (error) {
      console.error('Error processing speech:', error);
      return "I'm sorry, I had trouble understanding. Could you try again?";
    } finally {
      this.isProcessing = false;
    }
  }

  /**
   * Speak text to the room (convert to audio and publish)
   */
  private async speak(text: string): Promise<void> {
    console.log('Agent speaking:', text);

    // TODO: Implement text-to-speech
    // For now, we'll just log the text
    // In production:
    // 1. Convert text to audio using TTS (Cartesia/OpenAI)
    // 2. Create audio track
    // 3. Publish to room
  }

  /**
   * Disconnect from room
   */
  async disconnect(): Promise<void> {
    await this.room.disconnect();
    console.log('Agent disconnected');
  }

  /**
   * Get conversation history
   */
  getHistory(): CerebrasMessage[] {
    return this.conversationHistory;
  }
}

/**
 * Agent manager to handle multiple agents
 */
class AgentManager {
  private agents = new Map<string, LanguageTeacherAgent>();

  /**
   * Spawn a new agent for a room
   */
  async spawnAgent(
    roomName: string,
    url: string,
    token: string,
    metadata?: { difficulty?: DifficultyLevel; topic?: string }
  ): Promise<LanguageTeacherAgent> {
    const agent = new LanguageTeacherAgent();
    await agent.connect(url, token, metadata);

    this.agents.set(roomName, agent);
    console.log(`Agent spawned for room: ${roomName}`);

    return agent;
  }

  /**
   * Get agent for a room
   */
  getAgent(roomName: string): LanguageTeacherAgent | undefined {
    return this.agents.get(roomName);
  }

  /**
   * Remove agent for a room
   */
  async removeAgent(roomName: string): Promise<void> {
    const agent = this.agents.get(roomName);
    if (agent) {
      await agent.disconnect();
      this.agents.delete(roomName);
      console.log(`Agent removed for room: ${roomName}`);
    }
  }

  /**
   * Get all active agents
   */
  getActiveAgents(): string[] {
    return Array.from(this.agents.keys());
  }
}

export const agentManager = new AgentManager();
